{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weather Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this lecture, we will learn how to model weather data. We will use the data from the [National Oceanic and Atmospheric Administration (NOAA) Global Historical Climatology Network](https://www.ncdc.noaa.gov/data-access/land-based-station-data/land-based-datasets/global-historical-climatology-network-ghcn) (GHCN) to model the temperature in the United States. The GHCN is a database of daily climate records from thousands of land surface stations across the globe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Warning {.hide}\n",
    "\n",
    "::: {.callout-warning}\n",
    "Many simplifications have been made in order to complete this demonstration in the lecture period.  There are a number of things that could be done to improve how the data is retrieved and modeled.  It is intended to demonstrate functionality on how a Python application can be built to model weather data.\n",
    ":::\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API Token {.hide .smaller-85}\n",
    "\n",
    "To download the data, you will need to sign up for an API token on the NOAA website.  The National Climatic Data Center (NCDC) provides access to the GHCN data through Climate Data Online (CDO) web services. The API token is used to authenticate your requests to the CDO web services. You can sign up for an API token [here](https://www.ncdc.noaa.gov/cdo-web/token).\n",
    "\n",
    "![](./token-request.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Packages\n",
    "\n",
    "We will need the following Python packages to download and analyze the weather data:\n",
    "\n",
    "- `requests`: to make HTTP requests to the NOAA API\n",
    "- `pandas`: to work with tabular data\n",
    "- `matplotlib`: to create plots\n",
    "- `scipy`: to fit a model to the data\n",
    "- `python-dotenv`: to load the API token from the `.env` file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `requirements.txt` {.smaller-80}\n",
    "\n",
    "A requirements file is a simple text file that contains a list of Python packages that are required for the project. You can create a `requirements.txt` file in the same directory as this notebook with the following contents:\n",
    "\n",
    "```\n",
    "requests\n",
    "pandas\n",
    "matplotlib\n",
    "python-dotenv\n",
    "prophet\n",
    "jupyter\n",
    "ipywidgets\n",
    "plotly\n",
    "```\n",
    "\n",
    "You can install the required packages using the following command:\n",
    "\n",
    "```\n",
    "pip install -r requirements.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements Versioning {.smaller-90}\n",
    "\n",
    "You can specify the version of the required packages in the `requirements.txt` file.  This is referred to as \"pinning\" the versions of the required packages. For example, to require version 2.25.0 of the `requests` package, you can add the following line to the `requirements.txt` file:\n",
    "\n",
    "```\n",
    "requests==2.25.0\n",
    "```\n",
    "\n",
    "You can also specify a range of versions. For example, to require version 2.25.x of the `requests` package, you can add the following line to the `requirements.txt` file:\n",
    "\n",
    "```\n",
    "requests>=2.25.0,<2.26.0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API Data Endpoint {.smaller-75}\n",
    "\n",
    "The API is described in the [NOAA API documentation](https://www.ncdc.noaa.gov/cdo-web/webservices/v2). We will be using the following data endpoint `https://www.ncei.noaa.gov/cdo-web/api/v2/data` to download the weather data.\n",
    "\n",
    "We will specify the following parameters in the query string:\n",
    "\n",
    "- `datasetid=GHCND` (to specify the dataset Global Historical Climatology Network)\n",
    "- `stationid=GHCND:USW00093814` (to specify the Cincinnati/Northern Kentucky International Airport weather station)\n",
    "- `datatypeid=TMAX,TMIN`\n",
    "- `units=standard` (to specify standard units - Fahrenheit)\n",
    "- `startdate=<start_date>` (to specify the start date)\n",
    "- `enddate=<end_date>` (to specify the end date)\n",
    "- `limit=1000`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Curse of the Live Demo {.hide}\n",
    "\n",
    "The curse of the live demo ... appears to have been caused by **hurricane Helene!**\n",
    "\n",
    "![](./helene.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Token Security {.smaller-90}\n",
    "\n",
    "You should keep your API token secure. Do not share it with others or post it publicly. You can store your API token in a file named `.env` in the same directory as your code. The `.env` file should contain the following line:\n",
    "\n",
    "```\n",
    "NOAA_TOKEN=your-api-token\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Code {.hide .smaller-55}\n",
    "\n",
    "Let's make sure your API token is working by running the following code, which will download the weather data for the Cincinnati/Northern Kentucky International Airport weather station for the month of October 2024.\n",
    "\n",
    "```python\n",
    "import requests\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "noaa_token = os.getenv(\"NOAA_TOKEN\")\n",
    "\n",
    "base_url = \"https://www.ncdc.noaa.gov/cdo-web/api/v2\"\n",
    "data_endpoint = f\"{base_url}/data\"\n",
    "headers = {\"token\": noaa_token}\n",
    "\n",
    "params = {\n",
    "    \"datasetid\": \"GHCND\",\n",
    "    \"stationid\": \"GHCND:USW00093814\",\n",
    "    \"startdate\": \"2024-10-01\",\n",
    "    \"enddate\": \"2024-10-31\",\n",
    "    \"datatypeid\": \"TMAX,TMIN\",  # Only temperature data types\n",
    "    \"units\": \"standard\",  # Use standard units (Fahrenheit)\n",
    "    \"limit\": 1000\n",
    "}\n",
    "\n",
    "response = requests.get(\n",
    "    data_endpoint,\n",
    "    headers=headers,\n",
    "    params=params\n",
    ")\n",
    "\n",
    "response.raise_for_status()\n",
    "\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "\n",
    "## Print the first 5 results\n",
    "data['results'][:5]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Temperature Forecasting {.hide .smaller-85}\n",
    "\n",
    ":::: {.columns}\n",
    "\n",
    "::: {.column width=40%}\n",
    "For a basic temperature forecasting model, you should ideally have at least 3-5 years of historical data to capture seasonal patterns and year-to-year variations effectively. 10+ years is ideal for capturing longer-term patterns and climate trends.\n",
    ":::\n",
    "\n",
    "::: {.column width=60%}\n",
    "![](./usw00093814-station-details.png)\n",
    ":::\n",
    "\n",
    "::::\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `dataclass` {.hide .smaller-90}\n",
    "\n",
    "In Python, there is a special decorator called `dataclass` that can be used to create classes that are primarily used to store data. A `dataclass` automatically generates special methods such as `__init__`, `__repr__`, and `__eq__` for the class.  A `dataclass` is essentially a class that has boilerplate methods generated automatically.\n",
    "\n",
    "::: {.notes}\n",
    "- [Data Classes](https://docs.python.org/3/library/dataclasses.html)\n",
    "A data class is a class typically containing mainly data, without complex logic. Data classes are similar to namedtuples, but are more flexible.  Data classes are created using the `@dataclass` decorator.  Data classes are classes with boilerplate methods generated automatically.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `noaa.py` {.smaller-80}\n",
    "\n",
    "Create a new Python file named `noaa.py` and add the following code to define all of the imports that will be used in the file.:\n",
    "\n",
    "```python\n",
    "from dataclasses import dataclass\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import pandas as pd\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "from prophet import Prophet\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 {.hide .smaller-60}\n",
    "\n",
    "**Step 1**: We will create a `GHCNDStationTemps` dataclass to interact with the NOAA API and retrieve historical temperatures from a station.\n",
    "\n",
    "::: {.callout-info}\n",
    "Notice that there is no need to define the `__init__` method explicitly. The `dataclass` decorator automatically generates the `__init__` method for the class.\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "\n",
    "@dataclass\n",
    "class GHCNDStationTemps:\n",
    "    token: str\n",
    "    stationid: str\n",
    "    end_date: datetime = datetime.now().date() - timedelta(days=1)\n",
    "    years_of_history: int = 3\n",
    "    endpoint: str = \"https://www.ncdc.noaa.gov/cdo-web/api/v2/data\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Testing {.hide .smaller-60}\n",
    "\n",
    "```python\n",
    "from noaa import GHCNDStationTemps\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "token = os.getenv(\"NOAA_TOKEN\")\n",
    "stationid = \"GHCND:USW00014739\"\n",
    "ghcnd = GHCNDStationTemps(token, stationid, years_of_history=3)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 {.hide .smaller-60}\n",
    "\n",
    "**Step 2**: We will create a `fetch_data` method in the `GHCNDStationTemps` dataclass to fetch the historical temperature data from the NOAA API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def fetch_data(self):\n",
    "    if self.end_date is None:\n",
    "        self.end_date = datetime.now() - timedelta(days=1)\n",
    "\n",
    "    start_date = self.end_date - relativedelta(years=self.years_of_history)\n",
    "    current_date = start_date\n",
    "    all_data = []\n",
    "\n",
    "    while current_date < self.end_date:\n",
    "        chunk_end = min(current_date + relativedelta(years=1) - timedelta(days=1), self.end_date)\n",
    "        params = {\n",
    "            \"datasetid\": \"GHCND\",\n",
    "            \"stationid\": self.stationid,\n",
    "            \"datatypeid\": \"TMAX,TMIN\",\n",
    "            \"units\": \"standard\",\n",
    "            \"startdate\": current_date.strftime(\"%Y-%m-%d\"),\n",
    "            \"enddate\": chunk_end.strftime(\"%Y-%m-%d\"),\n",
    "            \"limit\": 1000,\n",
    "        }\n",
    "\n",
    "        print(f\"Fetching data from {current_date.date()} to {chunk_end.date()}...\")\n",
    "        response = requests.get(self.endpoint, headers={\"token\": self.token}, params=params)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        data = response.json()\n",
    "        if \"results\" in data:\n",
    "            all_data.extend(data[\"results\"])\n",
    "            print(f\"Retrieved {len(data['results'])} records.\")\n",
    "        else:\n",
    "            print(f\"No data found for {current_date.date()} to {chunk_end.date()}.\")\n",
    "\n",
    "        current_date = chunk_end + timedelta(days=1)\n",
    "\n",
    "    return all_data\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Testing {.hide .smaller-60}\n",
    "\n",
    "```python\n",
    "from noaa import GHCNDStationTemps\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "token = os.getenv(\"NOAA_TOKEN\")\n",
    "stationid = \"GHCND:USW00014739\"\n",
    "ghcnd = GHCNDStationTemps(token, stationid, years_of_history=3)\n",
    "\n",
    "ghcnd.fetch_data()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lazy Loading\n",
    "\n",
    "Lazy loading is a technique that delays the initialization of resources or objects until they are needed - this can help to improve performance. In our case, we are going to use lazy loading to fetch the data only when it is needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 {.hide .smaller-60}\n",
    "\n",
    "**Step 3**: Let's add a `data` property to the `GHCNDStationTemps` dataclass to return the historical temperature data.  This property will call the `fetch_data` method if the data is not already available.\n",
    "\n",
    "We will add a private `_data` attribute to the class to store the historical temperature data, initialized to `None`.\n",
    "\n",
    "```python\n",
    "_data = None\n",
    "```\n",
    "\n",
    "Next, modify the `fetch_data` method to be a private method by adding an underscore `_` to the method name.\n",
    "```python\n",
    "def _fetch_data(self):\n",
    "```\n",
    "\n",
    "Finally, we will define the `data` property to return the historical temperature data.\n",
    "```python\n",
    "@property\n",
    "def data(self):\n",
    "    if self._data is None:\n",
    "        print(\"Data is empty. Fetching data...\")\n",
    "        self._data = self.fetch_data()\n",
    "    return self._data\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Testing {.hide .smaller-60}\n",
    "\n",
    "```python\n",
    "from noaa import GHCNDStationTemps\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "token = os.getenv(\"NOAA_TOKEN\")\n",
    "stationid = \"GHCND:USW00014739\"\n",
    "ghcnd = GHCNDStationTemps(token, stationid, years_of_history=3)\n",
    "\n",
    "ghcnd.data\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4a {.hide .smaller-60}\n",
    "\n",
    "**Step 4a**: Let's modify `data` to return a `pandas` DataFrame instead of a list of dictionaries. Create a private `_convert_to_dataframe` static method to convert the raw data into a `pandas` DataFrame. \n",
    "\n",
    "```python\n",
    "@staticmethod\n",
    "def _convert_to_dataframe(all_data):\n",
    "    \"\"\"\n",
    "    Convert raw data into a pandas DataFrame with 'Date', 'TMAX', and 'TMIN' columns.\n",
    "    \"\"\"\n",
    "    # Convert to DataFrame and handle missing keys/values (e.g., NaN)\n",
    "    df = pd.DataFrame(all_data)\n",
    "\n",
    "    # Explicitly keep only the required columns\n",
    "    columns_to_keep = ['date', 'datatype', 'value']\n",
    "    if not all(col in df.columns for col in columns_to_keep):\n",
    "        raise ValueError(f\"Input data must contain these columns: {columns_to_keep}\")\n",
    "    \n",
    "    df = df[columns_to_keep]\n",
    "\n",
    "    # Pivot the table to get 'datatype' values as columns\n",
    "    df_pivot = df.pivot(index='date', columns='datatype', values='value')\n",
    "    # Remove the MultiIndex column formatting by renaming or flattening\n",
    "    df_pivot.columns.name = None\n",
    "    df_pivot = df_pivot.reset_index()\n",
    "\n",
    "    # Convert 'date' column to datetime.date type\n",
    "    df_pivot['date'] = pd.to_datetime(df_pivot['date']).dt.date\n",
    "    \n",
    "    # Rename columns for better readability\n",
    "    df_pivot.rename(columns={'TMAX': 'Max Temperature (°F)', \n",
    "                                'TMIN': 'Min Temperature (°F)',\n",
    "                                'date': 'Date'},\n",
    "                                inplace=True)\n",
    "\n",
    "    return df_pivot\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4b {.hide .smaller-60}\n",
    "\n",
    "**Step 4b**: Modify the `data` property to return a `pandas` DataFrame.\n",
    "\n",
    "```python\n",
    "@property\n",
    "def data(self):\n",
    "    if self._data is None:\n",
    "        print(\"Data is empty. Fetching and converting data...\")\n",
    "        raw_data = self._fetch_data()\n",
    "        self._data = self._convert_to_dataframe(raw_data)\n",
    "    return self._data\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Testing {.hide .smaller-60}\n",
    "\n",
    "```python\n",
    "from noaa import GHCNDStationTemps\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "token = os.getenv(\"NOAA_TOKEN\")\n",
    "stationid = \"GHCND:USW00014739\"\n",
    "ghcnd = GHCNDStationTemps(token, stationid, years_of_history=3)\n",
    "\n",
    "ghcnd.data\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5 {.hide .smaller-60}\n",
    "\n",
    "**Step 5**: Let's add a `plot` method to the `GHCNDStationTemps` dataclass to plot the historical temperature data.\n",
    "\n",
    "```python\n",
    "def plot_temperatures(self):\n",
    "    if self.data is None or self.data.empty:\n",
    "        print(\"No data available to plot.\")\n",
    "        return\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(self.data['Date'], self.data['Max Temperature (°F)'], label='Max Temperature (°F)', color='red')\n",
    "    plt.plot(self.data['Date'], self.data['Min Temperature (°F)'], label='Min Temperature (°F)', color='blue')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Temperature (°F)')\n",
    "    plt.title(f'Temperature Trends for Station {self.stationid}')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Testing {.hide .smaller-60}\n",
    "\n",
    "```python\n",
    "from noaa import GHCNDStationTemps\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "token = os.getenv(\"NOAA_TOKEN\")\n",
    "stationid = \"GHCND:USW00014739\"\n",
    "ghcnd = GHCNDStationTemps(token, stationid, years_of_history=3)\n",
    "\n",
    "ghcnd.data\n",
    "\n",
    "ghcnd.plot_temperatures()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6a {.hide .smaller-60}\n",
    "\n",
    "We are now ready to model the temperature data. We will use the `prophet` package to fit a time series model to the temperature data.  The `prophet` package is a forecasting tool developed by Facebook, it is described as a a modular regression model with interpretable parameters that can be intuitively adjusted by analysts with **domain knowledge** about the time series.\n",
    "\n",
    "![](./prophet.png)\n",
    "\n",
    ":::{.callout-info}\n",
    "This lecture isn't intended to provide a detailed explanation of time series modeling. For more information on time series modeling, refer to the [Prophet documentation](https://facebook.github.io/prophet/).  It is intended to demonstrate functionality on how a Python application can be built to model weather data.\n",
    ":::\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prophet {.smaller-65}\n",
    "\n",
    "Prophet uses a similar API to `sklearn` for fitting and predicting models. Specifically, you create an instance of the `Prophet` class and call its `fit` and `predict` methods.  \n",
    "\n",
    "The input to Prophet is a dataframe with two required columns: `ds` and `y`. The `ds` (datestamp) column should contain dates or timestamps in a format recognized by Pandas (e.g., YYYY-MM-DD for dates or YYYY-MM-DD HH:MM:SS for timestamps). The `y` column must be numeric and represents the variable to forecast. Ensure that `ds` contains unique values, as duplicate timestamps will result in errors.  \n",
    "\n",
    "By default, Prophet uses a linear growth model for its forecast. For scenarios where growth is constrained by a maximum achievable point—such as total market size or population size—Prophet allows you to use a logistic growth model. This requires specifying a carrying capacity, which represents the point at which growth saturates. To use the logistic growth model, add a `cap` column to your dataframe that defines the carrying capacity for each time point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Domain Knowledge {.hide .smaller-65}\n",
    "\n",
    "Do we need to use worry about the carrying capacity for temperature data?  **Probably not.**  The temperature data is unlikely to saturate at a certain point.  However, if you were modeling population growth, you would need to consider the carrying capacity.  Why Growth Models Aren’t Relevant for Temperature Forecasting:\n",
    "\n",
    "- **Temperature is Cyclical, Not Growth-Driven**\n",
    "  Temperature data is inherently cyclical (daily, seasonal, yearly patterns) rather than exhibiting sustained growth over time. Unlike datasets like sales or population, where there might be exponential or logistic growth trends, temperatures don’t have a \"carrying capacity\" or an upward trend that needs to be modeled in this way.\n",
    "\n",
    "- **Stable Mean Over Time**\n",
    "  While climate change can lead to long-term trends in temperature (e.g., gradual warming), these trends are slow and typically better modeled as part of a linear trend or external covariate (e.g., CO₂ levels), rather than requiring a growth model.\n",
    "\n",
    "- **Logistic Growth Doesn't Apply**\n",
    "  Logistic growth assumes a saturating maximum value, which makes sense for bounded phenomena like market size or biological populations. Temperature fluctuations, however, are bounded by physical realities (e.g., Earth's climate system) but do not \"grow\" towards a carrying capacity in the same way.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seasonality {.smaller-65}\n",
    "\n",
    "Prophet will by default fit weekly and yearly seasonalities.  Prophet models seasonality using a Fourier series representation --- which approximates periodic patterns (like yearly or weekly seasonality) using sine and cosine functions of different frequencies.  Yearly seasonality will use a default Fourier order of 10, and for weekly seasonality a default Fourier order of 3 is used.\n",
    "\n",
    ":::{.callout-info}\n",
    "While temperature exhibits yearly seasonality as its primary cycle (driven by seasons), there can also be sub-seasonal variations within months, especially in regions where temperatures change rapidly (e.g., spring or autumn transitions).\n",
    ":::\n",
    "\n",
    "You can add other seasonalities (monthly, quarterly, hourly) using the `add_seasonality` method (Python).\n",
    "The inputs to this function are a name, the period of the seasonality in days, and the Fourier order for the seasonality. \n",
    "\n",
    "```python\n",
    "model.add_seasonality(name='monthly', period=30.5, fourier_order=5)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6b {.hide .smaller-60}\n",
    "\n",
    "```python\n",
    "def forecast_daily_temperatures(self, n_periods=365, add_monthly_seasonality=False, plot_forecast=True):\n",
    "    if self.data is None or self.data.empty:\n",
    "        raise ValueError(\"No data available to forecast.\")\n",
    "\n",
    "    # Prepare data for Prophet\n",
    "    df = self.data[['Date', 'Max Temperature (°F)']].rename(\n",
    "        columns={'Date': 'ds', 'Max Temperature (°F)': 'y'})\n",
    "\n",
    "    # Initialize the Prophet model\n",
    "    # Prophet will by default fit weekly and yearly seasonalities\n",
    "    model = Prophet(\n",
    "        yearly_seasonality=True,  # Enable yearly seasonality\n",
    "        daily_seasonality=False,  # Disable daily seasonality unless needed\n",
    "        weekly_seasonality=False,  # Disable weekly seasonality unless needed\n",
    "    )\n",
    "\n",
    "    # Add additional seasonality if required (e.g., monthly or weekly)\n",
    "    if add_monthly_seasonality:\n",
    "        model.add_seasonality(name='monthly', period=30.5, fourier_order=5)\n",
    "    \n",
    "    # Fit the model\n",
    "    model.fit(df)\n",
    "    \n",
    "    # Create a dataframe for future dates\n",
    "    future = model.make_future_dataframe(periods=n_periods)  # Forecast for speicified number of periods\n",
    "\n",
    "    # Predict future values\n",
    "    forecast_df = model.predict(future)\n",
    "\n",
    "    if plot_forecast:\n",
    "        model.plot(forecast_df)\n",
    "        plt.title(f\"Temperature Forecast for Station {self.stationid}\")\n",
    "        plt.xlabel(\"Date\")\n",
    "        plt.ylabel(\"Temperature (°F)\")\n",
    "        plt.show()\n",
    "\n",
    "    return forecast_df\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Testing {.hide .smaller-60}\n",
    "\n",
    "```python\n",
    "from noaa import GHCNDStationTemps\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "token = os.getenv(\"NOAA_TOKEN\")\n",
    "stationid = \"GHCND:USW00014739\"\n",
    "ghcnd = GHCNDStationTemps(token, stationid, years_of_history=3)\n",
    "\n",
    "ghcnd.data\n",
    "\n",
    "ghcnd.plot_temperatures()\n",
    "\n",
    "forecast = ghcnd.forecast_daily_temperatures(n_periods=365, plot_forecast=True)\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
